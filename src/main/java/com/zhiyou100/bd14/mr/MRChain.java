package com.zhiyou100.bd14.mr;

import java.io.IOException;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.lib.chain.ChainMapper;
import org.apache.hadoop.mapreduce.lib.chain.ChainReducer;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.input.FileSplit;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

import com.zhiyou100.bd14.mr.DesDumplicate.DesDumolicateMap;

public class MRChain {
	private static Path path;

	//MapReudceä¸­ç»è¿‡çš„ç¬¬ä¸€ä¸ªMap, è¿‡æ»¤æ‰é”€å”®æ•°é‡å¤§äºä¸€äº¿çš„æ•°æ®
	public static class MRChainMap1 extends Mapper<LongWritable, Text, Text, IntWritable>{
		private Text outKey = new Text();
		private IntWritable outValue = new IntWritable();
		private String[] infos;
		
		@Override
		protected void setup(Mapper<LongWritable, Text, Text, IntWritable>.Context context)
				throws IOException, InterruptedException {
			FileSplit fileSplit = new FileSplit();
			path = fileSplit.getPath();
			System.out.println("** è¿›å…¥mapæ–¹æ³•:=================,è¯»å–æ–‡ä»¶:"+path);
		}

		@Override
		protected void map(LongWritable key, Text value, Mapper<LongWritable, Text, Text, IntWritable>.Context context)
				throws IOException, InterruptedException {
			//è¯»å–æ–‡ä»¶çš„ä¸€è¡Œçš„æ•°æ®:	å•†å“åç§°	ä»·æ ¼
			System.out.println("è¯»å–æ–‡ä»¶"+path+"çš„ä¸€è¡Œæ•°æ?"+value);
			infos = value.toString().split("\\s");
			if(Integer.valueOf(infos[1]) <= 100000000){
				outKey.set(infos[0]);
				outValue.set(Integer.valueOf(infos[1]));
				context.write(outKey, outValue);
			}
		}
	}


	//è¿‡æ»¤æ‰æ•°é‡åœ¨100-100000ä¹‹é—´çš„æ•°æ?
	public static class MRChainMap2 extends Mapper<Text, IntWritable, Text, IntWritable>{
		@Override
		protected void map(Text key, IntWritable value, Mapper<Text, IntWritable, Text, IntWritable>.Context context)
				throws IOException, InterruptedException {
			if(value.get() <= 100 || value.get() >= 10000){
				context.write(key, value);
			}
		}
	}

	
	//èšåˆå•†å“æ€»æ•°é‡?
	public static class MRChainReduce extends Reducer<Text, IntWritable, Text, IntWritable>{
		private int sum;
		private IntWritable outValue = new IntWritable();
		@Override
		protected void reduce(Text key, Iterable<IntWritable> values,
				Reducer<Text, IntWritable, Text, IntWritable>.Context context) throws IOException, InterruptedException {
			sum = 0;
			for(IntWritable value : values){
				sum +=value.get();
			}
			outValue.set(sum);
			context.write(key, outValue);
		}
	}
	
	//å•†å“åç§°å¤§äºä¸‰çš„è¿‡æ»¤æ?
	public static class MRChainMap3 extends Mapper<Text, IntWritable, Text, IntWritable>{
		@Override
		protected void map(Text key, IntWritable value, Mapper<Text, IntWritable, Text, IntWritable>.Context context)
				throws IOException, InterruptedException {
			if(key.getLength() < 3){
				context.write(key, value);
			}
		}
	}

	public static void main(String[] args) throws Exception {
		Configuration conf = new Configuration();
		Job job = Job.getInstance(conf);
		job.setJarByClass(DesDumolicateMap.class);
		job.setJobName("chain mapper");
		
		//è®¾ç½®mapç«¯æ‰§è¡?
		ChainMapper.addMapper(job, MRChainMap1.class, LongWritable.class, 
				Text.class, Text.class, IntWritable.class, conf);
		ChainMapper.addMapper(job, MRChainMap1.class, 
				Text.class, IntWritable.class, 
				Text.class, IntWritable.class, conf);
		
		//è®¾ç½®reduceç«¯æ‰§è¡?
		ChainReducer.setReducer(job, MRChainReduce.class, 
				Text.class, IntWritable.class, 
				Text.class, IntWritable.class, conf);
		ChainMapper.addMapper(job, MRChainMap1.class, 
				Text.class, IntWritable.class, 
				Text.class, IntWritable.class, conf);
		
		//è®¾ç½®è¾“å…¥æ•°æ®
		Path inputPath = new Path("/user/user-logs-large.txt");
		FileInputFormat.addInputPath(job, inputPath);
		
		//è®¾ç½®è¾“å‡ºæ•°æ®(ç›®å½•ä¸èƒ½ç›¸åŒ)
		Path outputPath = new Path("/bd14/data");
		//å¾—åˆ°hdfsæ–‡ä»¶ç®¡ç†ç³»ç»Ÿ, è¿›è¡Œé€’å½’åˆ é™¤, å…ˆè¿›è¡Œåˆ é™?
		outputPath.getFileSystem(conf).delete(outputPath,true);
		FileOutputFormat.setOutputPath(job, outputPath);
		
		//begin job
		System.exit(job.waitForCompletion(true)?0:1);
	}






















}
